{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !/usr/bin/python\n",
    "# -*- coding:utf-8 -*-\n",
    "# Author: yadi Lao\n",
    "import pickle\n",
    "import logging\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "def train_LR(x_train, y_train):\n",
    "    \"\"\"\n",
    "    训练逻辑回归\n",
    "    \"\"\"\n",
    "    x_train = StandardScaler().fit_transform(x_train)\n",
    "    parameters = {\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'C': [0.1, 1, 2, 5, 10, 20, 50, 100],\n",
    "    }\n",
    "    lr_model = LogisticRegression(C=1e5, solver='liblinear', multi_class='ovr', class_weight='balanced')\n",
    "    gsearch = RandomizedSearchCV(lr_model, param_distributions=parameters, scoring='f1', cv=3)\n",
    "    print('gridsearchcv fit begin...')\n",
    "    gsearch.fit(x_train, y_train)\n",
    "    print('Best score: {}'.format(gsearch.best_score_))\n",
    "    print('Best parameters set: {}'.format(gsearch.best_estimator_.get_params()))\n",
    "\n",
    "    lr_classifier = LogisticRegression(\n",
    "        penalty=gsearch.best_estimator_.get_params()['penalty'],\n",
    "        C=gsearch.best_estimator_.get_params()['C'],\n",
    "        class_weight=gsearch.best_estimator_.get_params()['class_weight']\n",
    "    )\n",
    "    lr_classifier.fit(x_train, y_train)\n",
    "    pickle.dump(lr_classifier, open('./save_model/pointwise/LR_{}.pkl'.format(feature_name), 'wb'))\n",
    "\n",
    "    return lr_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_GBDT(x_train, y_train, sample_weight=None):\n",
    "    \"\"\"\n",
    "    训练GBDT\n",
    "    \"\"\"\n",
    "    param_test1 = {'n_estimators': range(20, 81, 10),\n",
    "                   'subsample': [0.6, 0.7, 0.8, 0.85, 0.95],\n",
    "                   'max_depth': [4, 6, 8, 10, 15],\n",
    "                   }\n",
    "    gsearch = GridSearchCV(estimator=GradientBoostingClassifier(\n",
    "        learning_rate=0.1, min_samples_split=300, min_samples_leaf=20,\n",
    "        max_features='sqrt', random_state=10),\n",
    "        param_grid=param_test1, scoring='f1', iid=False, cv=3)\n",
    "    gsearch.fit(x_train, y_train)\n",
    "    print('Best score: {}'.format(gsearch.best_score_))\n",
    "    print('Best parameters set: {}'.format(gsearch.best_params_))\n",
    "\n",
    "    gbdt_classifier = GradientBoostingClassifier(\n",
    "        learning_rate=0.1,\n",
    "        min_samples_split=300,\n",
    "        min_samples_leaf=20,\n",
    "        max_features='sqrt',\n",
    "        max_depth=gsearch.best_params_['max_depth'],\n",
    "        subsample=gsearch.best_params_['subsample'],\n",
    "        n_estimators=gsearch.best_params_['n_estimators'])\n",
    "\n",
    "    gbdt_classifier.fit(x_train, y_train, sample_weight)\n",
    "    pickle.dump(gbdt_classifier, open('./save_model/pointwise/gbdt_{}.pkl'.format(feature_name), 'wb'))\n",
    "\n",
    "    return gbdt_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgboost(x_train, y_train):\n",
    "    \"\"\"\n",
    "    训练xgboost\n",
    "    \"\"\"\n",
    "    parameters = {\n",
    "        'max_depth': [4, 6, 8, 10, 15],\n",
    "        'learn_rate': [0.01, 0.02, 0.05, 0.1, 0.15],\n",
    "        'n_estimators': [100, 300, 500, 1000],\n",
    "        'min_child_weight': [0, 2, 5, 10, 20],\n",
    "        'subsample': [0.6, 0.7, 0.8, 0.85, 0.95],\n",
    "        'colsample_bytree': [0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "        'scale_pos_weight': [2,4,6,8,10],\n",
    "    }\n",
    "    model = xgb.sklearn.XGBClassifier(\n",
    "        nthread=5,\n",
    "        silent=False,\n",
    "        learn_rate=0.1,\n",
    "        max_depth=6,\n",
    "        min_child_weight=3,\n",
    "        subsample=0.7,\n",
    "        colsample_bytree=0.7,\n",
    "        objective='binary:logistic',\n",
    "        n_estimators=10)\n",
    "    gsearch = RandomizedSearchCV(model, param_distributions=parameters, scoring='f1', cv=3)\n",
    "    print('gridsearchcv fit begin...')\n",
    "    gsearch.fit(x_train, y_train)\n",
    "    print('Best score: {}'.format(gsearch.best_score_))\n",
    "    print('Best parameters set: {}'.format(gsearch.best_estimator_.get_params()))\n",
    "\n",
    "    xgb_classifier = xgb.sklearn.XGBClassifier(\n",
    "        nthread=gsearch.best_estimator_.get_params()['nthread'],\n",
    "        learn_rate=gsearch.best_estimator_.get_params()['learn_rate'],\n",
    "        learning_rate=gsearch.best_estimator_.get_params()['learning_rate'],\n",
    "        max_depth=gsearch.best_estimator_.get_params()['max_depth'],\n",
    "        min_child_weight=gsearch.best_estimator_.get_params()['min_child_weight'],\n",
    "        subsample=gsearch.best_estimator_.get_params()['subsample'],\n",
    "        colsample_bytree=gsearch.best_estimator_.get_params()['colsample_bytree'],\n",
    "        objective=gsearch.best_estimator_.get_params()['objective'],\n",
    "        n_estimators=gsearch.best_estimator_.get_params()['n_estimators'],\n",
    "        gamma=gsearch.best_estimator_.get_params()['gamma'],\n",
    "        reg_alpha=gsearch.best_estimator_.get_params()['reg_alpha'],\n",
    "        reg_lambda=gsearch.best_estimator_.get_params()['reg_lambda'],\n",
    "        max_delta_step=gsearch.best_estimator_.get_params()['max_delta_step'],\n",
    "        scale_pos_weight=gsearch.best_estimator_.get_params()['scale_pos_weight'],\n",
    "\n",
    "    )\n",
    "    watchlist = [(x_train, y_train), (x_test, y_test)]\n",
    "    xgb_classifier.fit(x_train, y_train, eval_set=watchlist, eval_metric='ndcg', early_stopping_rounds=10)\n",
    "    pickle.dump(xgb_classifier, open('./save_model/pointwise/xgboost_{}.pkl'.format(feature_name), 'wb'))\n",
    "\n",
    "    return xgb_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libsvm.python.svmutil import*\n",
    "from libsvm.python.svm import*\n",
    "\n",
    "\n",
    "def generate_format_file(x, y, output_file):\n",
    "    \"\"\"\n",
    "    生成规定格式的文件\n",
    "    \"\"\"\n",
    "    dim = x.shape[1]\n",
    "    with codecs.open(output_file, 'w') as fout:\n",
    "        for i, vec in enumerate(x):\n",
    "            if y[i] == 1:\n",
    "                label = '+1'\n",
    "            else:\n",
    "                label = '-1'\n",
    "            fea = list(map(lambda x: str(x[0])+':'+str(x[1]), list(zip(range(1, dim+1), vec))))\n",
    "            fea = ' '.join(fea)\n",
    "            fea = ' '.join([label, fea])\n",
    "            fout.write(fea + '\\n')\n",
    "            \n",
    "            \n",
    "# y_train, x_train = svm_read_problem(train_file)\n",
    "# y_test, x_test = svm_read_problem(test_file)\n",
    "# print('train={}, test={}'.format(len(x_train), len(x_test)))\n",
    "\n",
    "# rankSVM = svm_train(y_train, x_train, '-t 2 -c 4')\n",
    "# p_label, acc, val = svm_predict(y_test, x_test, rankSVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _to_list(x):\n",
    "    if isinstance(x, list):\n",
    "        returnx\n",
    "    return[x]\n",
    "\n",
    "\n",
    "def ndcg(y_true, y_pred, k=20, rel_threshold=0):\n",
    "    \"\"\"\n",
    "    calculate NDCG\n",
    "    \"\"\"\n",
    "    if k <= 0:\n",
    "        return 0\n",
    "    y_true = _to_list(np.squeeze(y_true).tolist())\n",
    "    y_pred = _to_list(np.squeeze(y_pred).tolist())\n",
    "    c = list(zip(y_true, y_pred))\n",
    "    random.shuffle(c)\n",
    "    c_g = sorted(c, key=lambda x: x[0], reverse=True)\n",
    "    c_p = sorted(c, key=lambda x: x[1], reverse=True)\n",
    "    idcg = 0\n",
    "    ndcg = 0\n",
    "    for i, (g, p) in enumerate(c_g):\n",
    "        if i >= k:\n",
    "            break\n",
    "        if g > rel_threshold:\n",
    "            idcg += (math.pow(2, g) - 1) / math.log(2+ i)\n",
    "    for i, (g, p) in enumerate(c_p):\n",
    "        if i >= k:\n",
    "            break\n",
    "        if g > rel_threshold:\n",
    "            ndcg += (math.pow(2, g) - 1) / math.log(2+ i)\n",
    "    if idcg == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return ndcg / idcg\n",
    "\n",
    "\n",
    "def grid_search(x_train, y_train):\n",
    "    ndcg_score = make_scorer(ndcg)\n",
    "    parameters = {\n",
    "        'max_depth': [4, 6, 8, 10, 15],\n",
    "        'learn_rate': [0.01, 0.02, 0.05, 0.1, 0.15],\n",
    "        'n_estimators': [100, 300, 500, 1000],\n",
    "        'min_child_weight': [0, 2, 5, 10, 20],\n",
    "        'subsample': [0.6, 0.7, 0.8, 0.85, 0.95],\n",
    "        'colsample_bytree': [0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "    }\n",
    "    model = xgb.sklearn.XGBClassifier(\n",
    "        nthread=5,\n",
    "        silent=False,\n",
    "        learn_rate=0.1,\n",
    "        max_depth=6,\n",
    "        min_child_weight=3,\n",
    "        subsample=0.7,\n",
    "        colsample_bytree=0.7,\n",
    "        objective='rank:pairwise',\n",
    "        n_estimators=10)\n",
    "    gsearch = RandomizedSearchCV(model, param_distributions=parameters, scoring=ndcg_score, cv=3)\n",
    "    print('gridsearchcv fit begin...')\n",
    "    gsearch.fit(x_train, y_train)\n",
    "    print('Best score: {}'.format(gsearch.best_score_))\n",
    "    print('Best parameters set: {}'.format(gsearch.best_estimator_.get_params()))\n",
    "\n",
    "    return gsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    # loadtrain andtest data\n",
    "    x_train, x_test, y_train, y_test = pickle.load(open(train_data_path, 'rb'))\n",
    "\n",
    "\n",
    "    if is_train:\n",
    "        model_id = len(os.listdir('./save_model/rankNet/{}'.format(feature_name)))\n",
    "        rankNet = RankNet.RankNet(in_dim=len(x_train[0]), n_units1=FC_DIM_1, n_units2=FC_DIM_2)\n",
    "\n",
    "        # optimizer: Adam, AdaGrad, SGD\n",
    "        rankNet.fit(\n",
    "            x_train, y_train, optimizerAlgorithm='SGD',\n",
    "            savemodelName='./save_model/rankNet/{}/model_{}'.format(feature_name, model_id),\n",
    "            savefigName='./save_model/rankNet/{}/fig_{}'.format(feature_name, model_id)\n",
    "        )\n",
    "        p_label = rankNet.predict(x_test)\n",
    "    else:\n",
    "        print('Load model')\n",
    "        model_name = './save_model/rankNet/{}/model_{}'.format(feature_name, model_id)\n",
    "        # model_name = './save_model/rankNet/model_5'\n",
    "        rankNet = RankNet.RankNet(\n",
    "            in_dim=len(x_train[0]), n_units1=FC_DIM_1, n_units2=FC_DIM_2, resumemodelName=model_name)\n",
    "        p_label = rankNet.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
